{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d30d65c",
   "metadata": {},
   "source": [
    "# Universitat Oberta de Catalunya  \n",
    "## Grado en Ingeniería Informática  \n",
    "### Trabajo Final de Grado (TFG)\n",
    "\n",
    "---\n",
    "\n",
    "## Sistema de recomendaciones basado en técnicas de aprendizaje automático para ampliar la exploración de géneros musicales \n",
    "**Autor:** Marc Fernández Pereira  \n",
    "**Bajo supervisión de:** Dra. María Moreno de Castro  \n",
    "**Área:** Inteligencia Artificial  \n",
    "**Semestre:** Otoño 2025  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e728c0c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Índice\n",
    "\n",
    "# 3. Fase de modelado\n",
    "\n",
    "\n",
    "## 3.1 Introducción\n",
    "\n",
    "El objetivo de esta fase es abordar tanto el desarrollo como la evaluación del modelo mediante distintas técnicas de aprendizaje no supervisado. Después de llevar a cabo un análisis exploratorio del conjunto de datos y de preparar el dataset con el que se trabajará, se procede a aplicar los algoritmos de *clustering* seleccionados con el fin de identificar patrones de similitud entre canciones basados en sus características musicales. Para cada resultado obtenido con cada uno de los modelo se redactará una breve descripción que permitirá al lector comprender los resultados sin necesidad de dominar los fundamentos básicos de las técnicas del aprendizaje profundo (*deep learning*). Al finalizar la tarea de modelado, se elaborará un análisis exhaustivo sobre el rendimiento de cada modelo para comparar cuál ofrece mejor resultado. \n",
    "\n",
    "## 3.2 Selección de las técnicas de modelado\n",
    "\n",
    "A continuación se propone el conjunto de técnicas de aprendizaje no supervisado que se abordarán en este proyecto:\n",
    "\n",
    "### 3.2.1 K-Means\n",
    "\n",
    "El algoritmo K-Means es un proceso iterativo que busca particionar el conjunto de datos en $k$ grupos con el objetivo minimizar la suma de distancias cuadráticas entre los puntos y los centroides de cada grupo formado. En cada iteración, las referencias de los centroides se actualizan con la media de los puntos asignados hasta que el proceso converge dando lugar a grupos estabilizados.\n",
    "\n",
    "Para establecer el valor $k$, habitualmente se utilizan diferentes técnicas como el método del codo (*Elbow method*), el criterio de la silueta (*Silhoutte Score*) o el índice de Calinski-Harabasz. En este proyecto se decide aplicar las tres técnicas con el objetivo de visualizar **cómo varía la calidad de agrupamiento** en función del número de clústeres y determinar el valor de $k$ que ofrezca el mejor equilibrio entre los grupos.\n",
    "\n",
    "En algoritmo K-Means funciona de la siguiente manera:\n",
    "\n",
    "1. En primer lugar se seleccionan el número de clústeres $k$ utilizando las técnicas anteriores. Que estas técnicas ofrezcan un valor $k$ determinado no implica tener que utilizar únicamente dicho valor, es importante destacar que se pueden generar agrupaciones entorno al valor $k$ que sugieren las técnicas.\n",
    "\n",
    "2. Acto seguido se inicializan las coordenadas de los centroides. Esto se puede realizar de manera aleatoria o simplemente indicando el valor inicial de manera manual. \n",
    "\n",
    "3. Se procede con la asignación de puntos a cada clúster utilizando una métrica de distancia como la euclidiana o la manhattan entre otros.\n",
    "\n",
    "4. Una vez se tienen los puntos del espacio asignados a un clúster determinado, se actualizan los centroides con la siguiente expresión:  \n",
    "    $$\n",
    "    \\mathbf{m}_i^{(t+1)} = \\frac{1}{|S_i^{(t)}|} \\sum_{\\mathbf{x}_j \\in S_i^{(t)}} \\mathbf{x}_j\n",
    "    $$  \n",
    "    donde:\n",
    "    - $\\mathbf{m}_i^{(t+1)}$: El nuevo centroide del clúster $i$ en la iteración $t + 1$\n",
    "    - $|S_i^{(t)}|$: Número de puntos pertenecientes al clúster $i$ en la iteración $t$ \n",
    "    - $x_j$: Representa cada punto del clúster \n",
    "\n",
    "5. Se repiten de manera iterativa los pasos 3 y 4 hasta que el algoritmo converge.\n",
    "\n",
    "Para que el algoritmo converja debe ocurrir que los centroides dejen de cambiar de clúster, llegados a este punto se tienen formado los clústeres que k-Means identifica en el conjunto de datos. \n",
    "\n",
    "\n",
    "### 3.2.2 K-Medoids\n",
    "\n",
    "K-Medoids también conocido como Partitioning Around Medoids (PAM) es un algoritmo de agrupamiento que se utiliza para dividir un conjunto de datos en $k$ grupos. A diferencia de K-Means donde se utiliza el cálculo de medias para establecer los centroides en cada iteración, en K-Medoids se utilizan puntos reales del conjunto de datos bajo el nombre de *medoids*. Este algoritmo es realmente eficiente sobre conjuntos de datos que presentan valores atípicos ya que los centroides se eligen como puntos reales del conjunto de datos en lugar de utilizarse las medias.\n",
    "\n",
    "Para realizar el agrupamiento de los datos a los medoids se utiliza el enfoque de PAM:\n",
    "\n",
    "1. Al igual que ocurre con k-Means se selecciona un valor $k$ utilizando las técnicas expuestas anteriormente.\n",
    "\n",
    "2. Se inicializa aleatoriamente los medoides eligiendo $k$ puntos reales del conjunto de datos.\n",
    "\n",
    "3. Se utiliza una métrica de distancia entre cada dato a los distintos medoides para agruparlo al medoide más cercano.\n",
    "\n",
    "4. Para cada clúster y una vez se realizan todas las asignaciones, se debe comprobar si alguno de los puntos del reduce el coeficiente de disimilitud, es decir, la suma de distancias dentro del grupo. Si se encuentra \n",
    "algún punto que cumpla esta condición se convertirá automáticamente en el nuevo medoide. \n",
    "\n",
    "5. Solamente que un medoide cambie, se realizará el proceso de nuevo.\n",
    "\n",
    "El algoritmo converge cuando todos los medoides no cambian en dos iteraciones seguidas. \n",
    "\n",
    "\n",
    "### 3.2.3 DBSCAN y OPTICS\n",
    "\n",
    "*Density-Based Spatial Clustering of Applications with Noise* (DBSCAN) y *Ordering Points To Identify The Clustering Structure*(OPTICS) son métodos de clustering no supervisado en que la agrupación está basada en la densidad de los datos. El método DBSCAN permite identificar patrones en un juego de datos agrupando los puntos que están más cercanos a alguna métrica como la distancia euclidiana o la manhattan. El método recibe dos parámetros, eps y minPoints:\n",
    "\n",
    "- **epsilon (eps)** : distancia máxima entre dos puntos para que uno sea considerado vecino del otro\n",
    "\n",
    "- **minPoints**: Establece el mínimo de puntos para que el método lo considere un clúster\n",
    "\n",
    "DBSCAN tiene la limitación de que trabaja con agrupación de densidades de datos fijas. El método OPTICS, podría considerarse una extensión de DBSCAN que ofrece la oportunidad de trabajar con agrupación de densidades variables. Además, el parámetro epsilon en OPTICS no determina la formación de clústeres sino que sirve para disminuir la complejidad de cálculo para el algoritmo.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695fd3d",
   "metadata": {},
   "source": [
    "<!-- # 3. Fase de modelado\n",
    "\n",
    "\n",
    "## 3.1 Introducción\n",
    "\n",
    "El objetivo de esta fase es abordar tanto el desarrollo como la evaluación del modelo mediante distintas técnicas de aprendizaje no supervisado. Después de llevar a cabo un análisis exploratorio del conjunto de datos y de preparar el dataset con el que se trabajará, se procede a aplicar los algoritmos de *clustering* seleccionados con el fin de identificar patrones de similitud entre canciones basados en sus características musicales. Para cada resultado obtenido con cada uno de los modelo se redactará una breve descripción que permitirá al lector comprender los resultados sin necesidad de dominar los fundamentos básicos de las técnicas del aprendizaje profundo (*deep learning*). Al finalizar la tarea de modelado, se elaborará un análisis exhaustivo sobre el rendimiento de cada modelo para comparar cuál ofrece mejor resultado. \n",
    "\n",
    "## 3.2 Selección de las técnicas de modelado\n",
    "\n",
    "A continuación se propone el conjunto de técnicas de aprendizaje no supervisado que se abordarán en este proyecto:\n",
    "\n",
    "### 3.2.1 K-Means\n",
    "\n",
    "El algoritmo K-Means es un proceso iterativo que busca particionar el conjunto de datos en $k$ grupos con el objetivo minimizar la suma de distancias cuadráticas entre los puntos y los centroides de cada grupo formado. En cada iteración, las referencias de los centroides se actualizan con la media de los puntos asignados hasta que el proceso converge dando lugar a grupos estabilizados.\n",
    "\n",
    "Para establecer el valor $k$, habitualmente se utilizan diferentes técnicas como el método del codo (*Elbow method*), el criterio de la silueta (*Silhoutte Score*) o el índice de Calinski-Harabasz. En este proyecto se decide aplicar las tres técnicas con el objetivo de visualizar **cómo varía la calidad de agrupamiento** en función del número de clústeres y determinar el valor de $k$ que ofrezca el mejor equilibrio entre los grupos.\n",
    "\n",
    "En algoritmo K-Means funciona de la siguiente manera:\n",
    "\n",
    "1. En primer lugar se seleccionan el número de clústeres $k$ utilizando las técnicas anteriores. Que estas técnicas ofrezcan un valor $k$ determinado no implica tener que utilizar únicamente dicho valor, es importante destacar que se pueden generar agrupaciones entorno al valor $k$ que sugieren las técnicas.\n",
    "\n",
    "2. Acto seguido se inicializan las coordenadas de los centroides. Esto se puede realizar de manera aleatoria o simplemente indicando el valor inicial de manera manual. \n",
    "\n",
    "3. Se procede con la asignación de puntos a cada clúster utilizando una métrica de distancia como la euclidiana o la manhattan entre otros.\n",
    "\n",
    "4. Una vez se tienen los puntos del espacio asignados a un clúster determinado, se actualizan los centroides con la siguiente expresión:  \n",
    "    $$\n",
    "    \\mathbf{m}_i^{(t+1)} = \\frac{1}{|S_i^{(t)}|} \\sum_{\\mathbf{x}_j \\in S_i^{(t)}} \\mathbf{x}_j\n",
    "    $$  \n",
    "    donde:\n",
    "    - $\\mathbf{m}_i^{(t+1)}$: El nuevo centroide del clúster $i$ en la iteración $t + 1$\n",
    "    - $|S_i^{(t)}|$: Número de puntos pertenecientes al clúster $i$ en la iteración $t$ \n",
    "    - $x_j$: Representa cada punto del clúster \n",
    "\n",
    "5. Se repiten de manera iterativa los pasos 3 y 4 hasta que el algoritmo converge.\n",
    "\n",
    "Para que el algoritmo converja debe ocurrir que los centroides dejen de cambiar de clúster, llegados a este punto se tienen formado los clústeres que k-Means identifica en el conjunto de datos. \n",
    "\n",
    "\n",
    "### 3.2.2 K-Medoids\n",
    "\n",
    "K-Medoids también conocido como Partitioning Around Medoids (PAM) es un algoritmo de agrupamiento que se utiliza para dividir un conjunto de datos en $k$ grupos. A diferencia de K-Means donde se utiliza el cálculo de medias para establecer los centroides en cada iteración, en K-Medoids se utilizan puntos reales del conjunto de datos bajo el nombre de *medoids*. Este algoritmo es realmente eficiente sobre conjuntos de datos que presentan valores atípicos ya que los centroides se eligen como puntos reales del conjunto de datos en lugar de utilizarse las medias.\n",
    "\n",
    "Para realizar el agrupamiento de los datos a los medoids se utiliza el enfoque de PAM:\n",
    "\n",
    "1. Al igual que ocurre con k-Means se selecciona un valor $k$ utilizando las técnicas expuestas anteriormente.\n",
    "\n",
    "2. Se inicializa aleatoriamente los medoides eligiendo $k$ puntos reales del conjunto de datos.\n",
    "\n",
    "3. Se utiliza una métrica de distancia entre cada dato a los distintos medoides para agruparlo al medoide más cercano.\n",
    "\n",
    "4. Para cada clúster y una vez se realizan todas las asignaciones, se debe comprobar si alguno de los puntos del reduce el coeficiente de disimilitud, es decir, la suma de distancias dentro del grupo. Si se encuentra \n",
    "algún punto que cumpla esta condición se convertirá automáticamente en el nuevo medoide. \n",
    "\n",
    "5. Solamente que un medoide cambie, se realizará el proceso de nuevo.\n",
    "\n",
    "El algoritmo converge cuando todos los medoides no cambian en dos iteraciones seguidas. \n",
    "\n",
    "\n",
    "### 3.2.3 DBSCAN y OPTICS\n",
    "\n",
    "*Density-Based Spatial Clustering of Applications with Noise* (DBSCAN) y *Ordering Points To Identify The Clustering Structure*(OPTICS) son métodos de clustering no supervisado en que la agrupación está basada en la densidad de los datos. El método DBSCAN permite identificar patrones en un juego de datos agrupando los puntos que están más cercanos a alguna métrica. El método recibe dos parámetros, eps y minPoints:\n",
    "\n",
    "- epsilon (eps) : distancia máxima entre dos puntos para que uno sea considerado vecino del otro\n",
    "\n",
    "- minPoints: Establece el mínimo de puntos para que el método lo considere un clúster\n",
    "\n",
    "DBSCAN tiene la limitación de que trabaja con agrupación de densidades de datos fijas. El método OPTICS, podría considerarse una extensión de DBSCAN que ofrece la oportunidad de trabajar con agrupación de densidades variables. Además, el parámetro epsilon en OPTICS no determina la formación de clústeres sino que sirve para disminuir la complejidad de cálculo para el algoritmo.\n",
    "\n",
    "\n",
    " -->\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
